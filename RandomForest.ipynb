{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "class CART:\n",
    "    def __init__(self, max_depth=None, min_samples_split=2, mode=\"regression\"):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.mode = mode\n",
    "        self.tree = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.tree = self._build_tree(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self._predict_row(row, self.tree) for row in X])\n",
    "    \n",
    "    def _build_tree(self, X, y, depth=0):\n",
    "        num_samples, num_features = X.shape\n",
    "        unique_values = np.unique(y)\n",
    "        # stop conditions\n",
    "        if len(unique_values) == 1 or (self.max_depth and depth == self.max_depth) or num_samples < self.min_samples_split:\n",
    "            if self.mode == 'regression':\n",
    "                return np.mean(y)\n",
    "            else:\n",
    "                return stats.mode(y, keepdims=False).mode\n",
    "        \n",
    "        best_split = None\n",
    "        best_score = float('inf')\n",
    "\n",
    "        for feature_idx in range(num_features):\n",
    "            # Sort the feature and corresponding labels\n",
    "            sorted_indices = np.argsort(X[:, feature_idx])\n",
    "            sorted_X = X[sorted_indices, feature_idx]\n",
    "            sorted_y = y[sorted_indices]\n",
    "            \n",
    "            if self.mode == 'regression':\n",
    "                left_sum = 0\n",
    "                right_sum = sorted_y.sum()\n",
    "                left_count = 0\n",
    "                right_count = num_samples\n",
    "                \n",
    "                for i in range(1, num_samples):  # Traverse sorted feature values\n",
    "                    left_sum += sorted_y[i - 1]\n",
    "                    right_sum -= sorted_y[i - 1]\n",
    "                    left_count += 1\n",
    "                    right_count -= 1\n",
    "\n",
    "                    if sorted_X[i] == sorted_X[i - 1]:  # Skip duplicate thresholds\n",
    "                        continue\n",
    "\n",
    "                    left_mean = left_sum / left_count\n",
    "                    right_mean = right_sum / right_count\n",
    "\n",
    "                    # Compute RSS\n",
    "                    left_rss = np.sum((sorted_y[:i] - left_mean) ** 2)\n",
    "                    right_rss = np.sum((sorted_y[i:] - right_mean) ** 2)\n",
    "                    score = (left_rss + right_rss) / num_samples\n",
    "\n",
    "                    # Update best split\n",
    "                    if score < best_score:\n",
    "                        best_score = score\n",
    "                        best_split = (feature_idx, (sorted_X[i] + sorted_X[i - 1]) / 2)\n",
    "            else:\n",
    "                left_counts = np.zeros(max(sorted_y) + 1)\n",
    "                right_counts = np.bincount(sorted_y, minlength=max(sorted_y) + 1)\n",
    "\n",
    "                for i in range(1, num_samples):\n",
    "                    left_counts[sorted_y[i - 1]] += 1\n",
    "                    right_counts[sorted_y[i - 1]] -= 1\n",
    "\n",
    "                    if sorted_X[i] == sorted_X[i - 1]:  # Skip duplicate thresholds\n",
    "                        continue\n",
    "\n",
    "                    left_prob = left_counts / left_counts.sum()\n",
    "                    right_prob = right_counts / right_counts.sum()\n",
    "\n",
    "                    left_gini = 1 - np.sum(left_prob ** 2)\n",
    "                    right_gini = 1 - np.sum(right_prob ** 2)\n",
    "                    score = (left_gini * left_counts.sum() + right_gini * right_counts.sum()) / num_samples\n",
    "\n",
    "                    # Update best split\n",
    "                    if score < best_score:\n",
    "                        best_score = score\n",
    "                        best_split = (feature_idx, (sorted_X[i] + sorted_X[i - 1]) / 2)\n",
    "\n",
    "        if best_split is None:\n",
    "            if self.mode == 'regression':\n",
    "                return np.mean(y)\n",
    "            else:\n",
    "                return stats.mode(y, keepdims=False).mode\n",
    "\n",
    "        # Recursively build left and right subtrees\n",
    "        feature_idx, threshold = best_split\n",
    "        left_mask = X[:, feature_idx] <= threshold\n",
    "        right_mask = ~left_mask\n",
    "        left_tree = self._build_tree(X[left_mask], y[left_mask], depth + 1)\n",
    "        right_tree = self._build_tree(X[right_mask], y[right_mask], depth + 1)\n",
    "        \n",
    "        return {\n",
    "            'best_split': best_split,\n",
    "            'left': left_tree,\n",
    "            'right': right_tree\n",
    "        }\n",
    "\n",
    "    def _predict_row(self, row, tree):\n",
    "        if isinstance(tree, dict):\n",
    "            feature, threshold = tree['best_split']\n",
    "            if row[feature] <= threshold:\n",
    "                return self._predict_row(row, tree['left'])\n",
    "            else:\n",
    "                return self._predict_row(row, tree['right'])\n",
    "        else:\n",
    "            return tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeClassifier, DecisionTreeRegressor\n",
    "class RandomForest:\n",
    "    def __init__(self, n_estimators=10, max_depth=None, min_samples_split=2, max_features='sqrt', oob_score=False, mode=\"regression\", random_state=0, n_jobs=-1):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_features = max_features\n",
    "        self.oob_score = oob_score\n",
    "        self.oob_score_ = None  # 用于存储OOB得分\n",
    "        self.mode = mode\n",
    "        self.random_state = random_state\n",
    "        self.n_jobs = n_jobs\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.estimators = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        np.random.seed(self.random_state)\n",
    "        if not isinstance(y, np.ndarray):\n",
    "            y = np.array(y)\n",
    "        \n",
    "        # 并行训练每棵树\n",
    "        self.estimators = Parallel(n_jobs=self.n_jobs)(\n",
    "            delayed(self._train_tree)(X, y, i)\n",
    "            for i in range(self.n_estimators)\n",
    "        )\n",
    "        \n",
    "        # 计算袋外得分\n",
    "        if self.oob_score:\n",
    "            self._cal_oob_score(X, y)\n",
    "    \n",
    "    def _train_tree(self, X, y, i):\n",
    "        np.random.seed(self.random_state + i)\n",
    "        num_samples, num_features = X.shape\n",
    "        \n",
    "        # boostrap\n",
    "        sample_idx = np.random.choice(num_samples, size=num_samples, replace=True)\n",
    "        X_k, y_k = X[sample_idx], y[sample_idx]\n",
    "        \n",
    "        if self.max_features == 'sqrt':\n",
    "            feature_idx = np.random.choice(num_features, size=int(np.sqrt(num_features)), replace=False)\n",
    "        elif self.max_features == 'log2':\n",
    "            feature_idx = np.random.choice(num_features, size=int(np.log2(num_features)), replace=False)\n",
    "        else:\n",
    "            feature_idx = np.random.choice(num_features, size=num_features, replace=False)\n",
    "        \n",
    "        estimator = CART(self.max_depth, self.min_samples_split, self.mode)\n",
    "        estimator.fit(X_k[:, feature_idx], y_k)\n",
    "        return (estimator, feature_idx, sample_idx)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        y_pred = []\n",
    "        for estimator, feature_idx, _ in self.estimators:\n",
    "            y_pred.append(estimator.predict(X[:, feature_idx]))\n",
    "        y_pred = np.array(y_pred).T\n",
    "        self._y_pred = y_pred\n",
    "        if self.mode == 'classification':\n",
    "            y_pred = stats.mode(y_pred, axis=1, keepdims=False).mode\n",
    "        elif self.mode == 'regression':\n",
    "            y_pred = np.mean(y_pred, axis=1)\n",
    "        return y_pred\n",
    "    \n",
    "    def _cal_oob_score(self, X, y):\n",
    "        num_samples, num_features = X.shape\n",
    "        if self.mode == \"regression\":\n",
    "            oob_predictions = np.zeros(num_samples)  # 存储袋外样本的预测结果\n",
    "        else:\n",
    "            oob_predictions = [[] for _ in range(num_samples)]\n",
    "        oob_count = np.zeros(num_samples)  # 记录每个样本被多少棵树预测过\n",
    "        for estimator, feature_idx, sample_idx in self.estimators:\n",
    "            oob_idx = np.setdiff1d(np.arange(num_samples), sample_idx)\n",
    "            # 对袋外样本进行预测\n",
    "            for idx in oob_idx:\n",
    "                oob_count[idx] += 1\n",
    "                y_pred_oob = estimator._predict_row(X[idx, feature_idx], estimator.tree)\n",
    "\n",
    "                if self.mode == \"regression\":\n",
    "                    oob_predictions[idx] += y_pred_oob  # 回归任务是累加\n",
    "                else:\n",
    "                    oob_predictions[idx].append(y_pred_oob)  # 分类时采用投票\n",
    "        mask = oob_count > 0\n",
    "        if self.mode == \"regression\":\n",
    "            # 计算R方\n",
    "            oob_predictions = oob_predictions[mask] / oob_count[mask]  # 对每个样本的袋外预测结果进行平均\n",
    "            self.oob_score_ = 1 - np.sum((oob_predictions - y[mask]) ** 2) / np.sum((y[mask] - y[mask].mean()) ** 2)\n",
    "        else:\n",
    "            # 计算分类准确率\n",
    "            oob_predictions = np.array([stats.mode(predictions, keepdims=False).mode for predictions in oob_predictions if predictions])\n",
    "            self.oob_score_ = np.mean(oob_predictions == y[mask])  # 计算准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "自实现 RandomForest 分类准确率: 1.0\n",
      "sklearn RandomForest 分类准确率: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris, make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "\n",
    "# 加载Iris数据集\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# 拆分数据集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 使用你实现的RandomForest进行训练\n",
    "rf_custom = CART(max_depth=3, mode=\"classification\")\n",
    "rf_custom.fit(X_train, y_train)\n",
    "y_pred_custom = rf_custom.predict(X_test)\n",
    "\n",
    "# 使用sklearn的RandomForestClassifier进行训练\n",
    "rf_sklearn = RandomForestClassifier(n_estimators=10, max_depth=3, random_state=42, oob_score=True)\n",
    "rf_sklearn.fit(X_train, y_train)\n",
    "y_pred_sklearn = rf_sklearn.predict(X_test)\n",
    "\n",
    "# 对比预测结果\n",
    "accuracy_custom = accuracy_score(y_test, y_pred_custom)\n",
    "accuracy_sklearn = accuracy_score(y_test, y_pred_sklearn)\n",
    "\n",
    "print(\"自实现 RandomForest 分类准确率:\", accuracy_custom)\n",
    "# print('oob score:', rf_custom.oob_score_)\n",
    "print(\"sklearn RandomForest 分类准确率:\", accuracy_sklearn)\n",
    "# print('sklearn oob score:', rf_sklearn.oob_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "自实现 RandomForest 回归 MSE: 3251.148483710497\n",
      "sklearn RandomForest 回归 MSE: 3283.8371794334876\n"
     ]
    }
   ],
   "source": [
    "RANDOM_STATE = 45\n",
    "# 生成回归数据集\n",
    "X, y = make_regression(n_samples=100, n_features=5, noise=0.1, random_state=RANDOM_STATE)\n",
    "\n",
    "# 拆分数据集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE)\n",
    "\n",
    "# 使用你实现的RandomForest进行训练\n",
    "rf_custom = CART(max_depth=3, mode=\"regression\")\n",
    "rf_custom.fit(X_train, y_train)\n",
    "y_pred_custom = rf_custom.predict(X_test)\n",
    "\n",
    "# 使用sklearn的RandomForestRegressor进行训练\n",
    "rf_sklearn = RandomForestRegressor(n_estimators=10, \n",
    "                                max_depth=3, \n",
    "                                random_state=RANDOM_STATE,\n",
    "                                max_features='sqrt',\n",
    "                                oob_score=True)\n",
    "rf_sklearn.fit(X_train, y_train)\n",
    "y_pred_sklearn = rf_sklearn.predict(X_test)\n",
    "\n",
    "# 对比预测结果\n",
    "mse_custom = mean_squared_error(y_test, y_pred_custom)\n",
    "mse_sklearn = mean_squared_error(y_test, y_pred_sklearn)\n",
    "\n",
    "print(\"自实现 RandomForest 回归 MSE:\", mse_custom)\n",
    "# print('自实现 oob score:', rf_custom.oob_score_)\n",
    "print(\"sklearn RandomForest 回归 MSE:\", mse_sklearn)\n",
    "# print('sklearn oob score:', rf_sklearn.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 124.15,  185.1 ,  133.92,  143.8 ,   15.7 ,  132.54,  150.33,\n",
       "         151.49,  140.75,  183.31],\n",
       "       [ -40.28, -136.48,   12.6 ,  -89.34, -181.74,  -56.52, -217.28,\n",
       "        -262.02,  -91.14, -168.82],\n",
       "       [  93.01,  -12.48,   50.56,   87.65,   84.8 ,   85.43,  -43.82,\n",
       "          47.82,   45.74,   75.78],\n",
       "       [ 124.15,  185.1 ,  133.92,  143.8 ,  -15.5 ,  132.54,   82.67,\n",
       "        -148.34,  237.32, -168.82],\n",
       "       [ 124.15,  185.1 ,  133.92,  143.8 ,   15.7 ,  132.54,  150.33,\n",
       "         -16.8 ,  237.32,  -89.56],\n",
       "       [ -40.28,  -12.48,   50.56,   87.65,   15.7 ,  -56.52,  176.52,\n",
       "         151.49,   45.74,  183.31],\n",
       "       [ 124.15,  185.1 ,  133.92,  143.8 ,   15.7 ,  132.54,  150.33,\n",
       "         -16.8 ,  140.75,   60.35],\n",
       "       [   0.2 , -136.48, -217.84,  -79.92,   15.7 ,   85.43,  -43.82,\n",
       "          47.82,  -91.14,   75.78],\n",
       "       [ 359.27,   72.11,   27.69,  143.8 ,  -15.5 ,  132.54,   82.67,\n",
       "          47.82,   45.74,   70.16],\n",
       "       [ -40.28, -136.48, -217.84,  -89.34,   15.7 ,  -56.52,  -43.82,\n",
       "          47.82,   43.57,   75.78],\n",
       "       [ 359.27,   72.11,   27.69,  359.27,   84.8 ,  132.54,  -40.47,\n",
       "          47.82,  140.75,   75.78],\n",
       "       [   0.2 , -136.48, -217.84,  -79.92,   15.7 ,   85.43,  -43.82,\n",
       "          40.2 ,  -91.14,  183.31],\n",
       "       [ -40.28,  -38.58,   27.69,   87.65,   15.7 ,  -56.52,  -43.82,\n",
       "        -108.58, -136.58,   75.78],\n",
       "       [ 124.15,  -40.47,   27.69,  143.8 ,  -40.47,  132.54,   82.67,\n",
       "        -148.34,  237.32, -168.82],\n",
       "       [-152.99,  -12.48,   50.56,   87.65,   84.8 ,  -56.52,  -43.82,\n",
       "          47.82,  -91.14,   75.78],\n",
       "       [ -40.28,  -38.58,   50.56,  -89.34,   15.7 , -180.32,  -43.82,\n",
       "        -126.43,   45.74,   60.35],\n",
       "       [   0.2 ,  -12.48,   50.56,   87.65,   15.7 ,  -56.52,  -43.82,\n",
       "          47.82, -136.58,   75.78],\n",
       "       [ -40.28,  -12.48,   50.56,   87.65,   84.8 ,  -56.52,  -43.82,\n",
       "          47.82,   45.74,   75.78],\n",
       "       [  93.01,  -12.48,   50.56,   87.65,   84.8 ,  244.56,  -43.82,\n",
       "          47.82, -136.58,   75.78],\n",
       "       [ -40.28,  -12.48,  133.92,  -89.34,   84.8 ,  -56.52,  -43.82,\n",
       "          47.82,   45.74,   75.78]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.set_printoptions(precision=2, suppress=True)\n",
    "rf_custom.y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Value\n",
    "class MyClass:\n",
    "    def __init__(self, x):\n",
    "        self.x = x\n",
    "        self.loop = 10\n",
    "\n",
    "    def fit(self):\n",
    "\n",
    "        Parallel(n_jobs=2)(delayed(self.fun)(i) for i in range(self.loop))\n",
    "\n",
    "    def fun(self, i):\n",
    "        self.x += 1\n",
    "        print(i)\n",
    "\n",
    "a = MyClass(0)\n",
    "a.fit()\n",
    "print(a.x)  # 输出应该是 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "PicklingError",
     "evalue": "Could not pickle the task to send it to the workers.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\Users\\62687\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\backend\\queues.py\", line 153, in _feed\n    obj_ = dumps(obj, reducers=reducers)\n  File \"c:\\Users\\62687\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\backend\\reduction.py\", line 271, in dumps\n    dump(obj, buf, reducers=reducers, protocol=protocol)\n  File \"c:\\Users\\62687\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\backend\\reduction.py\", line 264, in dump\n    _LokyPickler(file, reducers=reducers, protocol=protocol).dump(obj)\n  File \"c:\\Users\\62687\\anaconda3\\lib\\site-packages\\joblib\\externals\\cloudpickle\\cloudpickle_fast.py\", line 602, in dump\n    return Pickler.dump(self, obj)\n  File \"c:\\Users\\62687\\anaconda3\\lib\\multiprocessing\\sharedctypes.py\", line 199, in __reduce__\n    assert_spawning(self)\n  File \"c:\\Users\\62687\\anaconda3\\lib\\multiprocessing\\context.py\", line 373, in assert_spawning\n    raise RuntimeError(\nRuntimeError: Synchronized objects should only be shared between processes through inheritance\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[38;5;28mprint\u001b[39m(i)\n\u001b[0;32m     19\u001b[0m a \u001b[38;5;241m=\u001b[39m MyClass(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 20\u001b[0m \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(a\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mvalue)\n",
      "Cell \u001b[1;32mIn[37], line 11\u001b[0m, in \u001b[0;36mMyClass.fit\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m# 使用 Parallel 来并行化调用 fun 方法\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m     \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfun\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloop\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\62687\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:1061\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1058\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1060\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1061\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1062\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1063\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[1;32mc:\\Users\\62687\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:938\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    936\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    937\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 938\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    939\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    940\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[1;32mc:\\Users\\62687\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    539\u001b[0m \u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    540\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    541\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 542\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    543\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    544\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\62687\\anaconda3\\lib\\concurrent\\futures\\_base.py:458\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    460\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "File \u001b[1;32mc:\\Users\\62687\\anaconda3\\lib\\concurrent\\futures\\_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mPicklingError\u001b[0m: Could not pickle the task to send it to the workers."
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "from multiprocessing import Value\n",
    "\n",
    "class MyClass:\n",
    "    def __init__(self, x):\n",
    "        self.x = Value('i', x)  # 创建一个共享变量 'x'\n",
    "        self.loop = 10\n",
    "\n",
    "    def fit(self):\n",
    "        # 使用 Parallel 来并行化调用 fun 方法\n",
    "        Parallel(n_jobs=2)(delayed(self.fun)(i) for i in range(self.loop))\n",
    "\n",
    "    def fun(self, i):\n",
    "        # 更新共享变量 x\n",
    "        with self.x.get_lock():  # 使用锁来保证对共享变量的安全访问\n",
    "            self.x.value += 1\n",
    "        print(i)\n",
    "\n",
    "a = MyClass(0)\n",
    "a.fit()\n",
    "print(a.x.value)  # 输出应该是 10"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
